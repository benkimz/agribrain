{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJCEk6knxBL2",
        "outputId": "6e8ba26b-ece0-4b1d-d030-f92831f71f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFshI-ajgkrm"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSEaTFzqhATU",
        "outputId": "3fe2c766-7919-48d7-895e-807c2b152604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli repo create agbrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIjaNKm9hE09",
        "outputId": "2236dc2a-19ce-4218-a8b1-922c40e022c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90mgit version 2.25.1\u001b[0m\n",
            "\u001b[90mgit-lfs/2.9.2 (GitHub; linux amd64; go 1.13.5)\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1mbenkimz/agbrain\u001b[0m\n",
            "Proceed? [Y/n] Y\n",
            "\n",
            "Your repo now lives at:\n",
            "  \u001b[1mhttps://huggingface.co/benkimz/agbrain\u001b[0m\n",
            "\n",
            "You can clone it locally with the command below, and commit/push as usual.\n",
            "\n",
            "  git clone https://huggingface.co/benkimz/agbrain\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/benkimz/agbrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcS7njs6hhAl",
        "outputId": "d02b9eee-7dac-4dad-da04-2c4c2aef12b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'agbrain'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), 420 bytes | 420.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./agbrain/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmuMzkS9htLp",
        "outputId": "f1bbe238-d340-45e1-995c-1e410f3d3354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/agbrain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "L6WyAJ1gxjI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ../drive/MyDrive/agribrain/aicore/agbrain/* . "
      ],
      "metadata": {
        "id": "8hQWoyHEh1Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNDXsq2IiYmP",
        "outputId": "eecf6744-106c-416f-a3b9-4eddee5a7e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t\tpytorch_model.bin\t tokenizer_config.json\n",
            "generation_config.json\tspecial_tokens_map.json  training_args.bin\n",
            "merges.txt\t\ttf_model.h5\t\t vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs track \"*.h5\"\n",
        "!git lfs track \"*.bin\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgDy_3FxidUK",
        "outputId": "3efe4a94-9441-4066-ffe1-b1472cdd1fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"*.h5\" already supported\n",
            "\"*.bin\" already supported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add . "
      ],
      "metadata": {
        "id": "Hy6j8EW4jCqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email benkim3619@gmail.com\n",
        "!git config --global user.name benkimz"
      ],
      "metadata": {
        "id": "Zj9wtfmhjVlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Pushing AgriBrain's AI-core to huggingface\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRT6zLgljF4V",
        "outputId": "b884bbb4-c3f6-443c-b98c-28c431b4c7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 59c5c10] Pushing AgriBrain's AI-core to huggingface\n",
            " 9 files changed, 100370 insertions(+)\n",
            " create mode 100644 config.json\n",
            " create mode 100644 generation_config.json\n",
            " create mode 100644 merges.txt\n",
            " create mode 100644 pytorch_model.bin\n",
            " create mode 100644 special_tokens_map.json\n",
            " create mode 100644 tf_model.h5\n",
            " create mode 100644 tokenizer_config.json\n",
            " create mode 100644 training_args.bin\n",
            " create mode 100644 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push --force origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCEo9rXjjUBE",
        "outputId": "a3408c1e-ad1e-4b7a-beb5-509df16bf8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading LFS objects: 100% (3/3), 1.0 GB | 54 MB/s, done.\n",
            "Enumerating objects: 12, done.\n",
            "Counting objects: 100% (12/12), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (11/11), done.\n",
            "Writing objects: 100% (11/11), 522.08 KiB | 4.70 MiB/s, done.\n",
            "Total 11 (delta 0), reused 0 (delta 0)\n",
            "To https://huggingface.co/benkimz/agbrain\n",
            "   834bb84..59c5c10  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6crjaKKYjpL_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}