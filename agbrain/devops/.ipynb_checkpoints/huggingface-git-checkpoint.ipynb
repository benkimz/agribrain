{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OFshI-ajgkrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67cc1e1-7930-452d-ca89-06cfb610f732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSEaTFzqhATU",
        "outputId": "3b4c6cdf-392c-43ef-8b49-fd2ffc81f1c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli repo create agbrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIjaNKm9hE09",
        "outputId": "a38e7cbb-e289-435c-b755-e2820bea5ab9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90mgit version 2.25.1\u001b[0m\n",
            "\u001b[90mgit-lfs/2.9.2 (GitHub; linux amd64; go 1.13.5)\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1mbenkimz/agbrain\u001b[0m\n",
            "Proceed? [Y/n] Y\n",
            "\n",
            "Your repo now lives at:\n",
            "  \u001b[1mhttps://huggingface.co/benkimz/agbrain\u001b[0m\n",
            "\n",
            "You can clone it locally with the command below, and commit/push as usual.\n",
            "\n",
            "  git clone https://huggingface.co/benkimz/agbrain\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/benkimz/agbrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcS7njs6hhAl",
        "outputId": "d85869a4-9992-4b60-fba0-7a91f664c89a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'agbrain'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), 420 bytes | 420.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./agbrain/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmuMzkS9htLp",
        "outputId": "76344df8-59c2-44c0-d49f-ead0fb5f269b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/agbrain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ../drive/MyDrive/agribrain/aicore/agbrain/* . "
      ],
      "metadata": {
        "id": "8hQWoyHEh1Cz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNDXsq2IiYmP",
        "outputId": "2801fc6b-00cf-4a3b-c5eb-d142ae09634d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t\tpytorch_model.bin\t tokenizer_config.json\n",
            "generation_config.json\tspecial_tokens_map.json  training_args.bin\n",
            "merges.txt\t\ttf_model.h5\t\t vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs track \"*.h5\"\n",
        "!git lfs track \"*.bin\"\n",
        "!git lfs track \"*.json\"\n",
        "!git lfs track \"*.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgDy_3FxidUK",
        "outputId": "8918375c-1981-432d-e141-8dccd5680806"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"*.h5\" already supported\n",
            "\"*.bin\" already supported\n",
            "Tracking \"*.json\"\n",
            "Tracking \"*.txt\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add . "
      ],
      "metadata": {
        "id": "Hy6j8EW4jCqv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email benkim3619@gmail.com\n",
        "!git config --global user.name benkimz"
      ],
      "metadata": {
        "id": "Zj9wtfmhjVlq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Pushing AgriBrain's AI-core to huggingface\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRT6zLgljF4V",
        "outputId": "6d118683-04c9-4651-c769-c93be13dd204"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main c9f9a05] Pushing AgriBrain's AI-core to huggingface\n",
            " 10 files changed, 29 insertions(+)\n",
            " create mode 100644 config.json\n",
            " create mode 100644 generation_config.json\n",
            " create mode 100644 merges.txt\n",
            " create mode 100644 pytorch_model.bin\n",
            " create mode 100644 special_tokens_map.json\n",
            " create mode 100644 tf_model.h5\n",
            " create mode 100644 tokenizer_config.json\n",
            " create mode 100644 training_args.bin\n",
            " create mode 100644 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push --force origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCEo9rXjjUBE",
        "outputId": "6105be74-4dab-47e2-afd8-4a228245f9e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading LFS objects: 100% (9/9), 1.0 GB | 103 MB/s, done.\n",
            "Enumerating objects: 14, done.\n",
            "Counting objects: 100% (14/14), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (12/12), done.\n",
            "Writing objects: 100% (12/12), 1.68 KiB | 1.68 MiB/s, done.\n",
            "Total 12 (delta 1), reused 0 (delta 0)\n",
            "To https://huggingface.co/benkimz/agbrain\n",
            "   5a41619..c9f9a05  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6crjaKKYjpL_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}